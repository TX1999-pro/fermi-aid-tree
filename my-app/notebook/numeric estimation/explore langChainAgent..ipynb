{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore langChain agent in handling numeric estimation tasks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Use langChain agent to output reliable result.\n",
    "\n",
    "## Task\n",
    "we are tackling the task of mathematical computation.\n",
    "-> already failed - rounding error\n",
    "-> use step function? -> not useful\n",
    "-> conclusion: langChain agent isn't easy to customised. The prompt wrapper is likely to contaminate the desired behaviour, and therefore it is extremly difficult to dictate model behavior.\n",
    "\n",
    "## repot\n",
    "Will not mention, but I can introduce this discovery in viva.\n",
    "\n",
    "Benchmark\n",
    "1. test suite designed with hardcoded python logic that embed randomly generated number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install langchain\n",
    "%pip install python-dotenv\n",
    "%pip install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain\n",
    "\n",
    "A chain is made up from 'links'.\n",
    "\n",
    "Types:\n",
    "1. LLMChain = PromptTemplate + LLM\n",
    "2. Agent - handle user input, pick tools/toolkits, and respond\n",
    "3. Tool - functions that the agent use to execute / take actions\n",
    "4. Toolkit - a set of tools for certain tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "## set up LLM\n",
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "## set up prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "## create a chain (or, chain the action)\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "output = chain.run(\"beautiful socks\").strip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent\n",
    "Agent will dynamically call chains based on user input. HOW?\n",
    "\n",
    "It will use LLM to determine which actions to take, and in what order.\n",
    "\n",
    "Actions include:\n",
    "1. use a tool and 'observe' the output\n",
    "2. return to user\n",
    "\n",
    "Documents: \n",
    "- Agents: [supported agents and their specifications](https://python.langchain.com/en/latest/modules/agents/getting_started.html)\n",
    "- Tools: [predefined tools and their specifications](https://python.langchain.com/en/latest/modules/agents/tools/getting_started.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "# First, let's load the language model we're going to use to control the agent. ()\n",
    "gpt3 = OpenAI(temperature=0,model_name=\"text-davinci-003\")\n",
    "\n",
    "# Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"llm-math\"], llm=gpt3)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, gpt3, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to break down the problem into smaller, more manageable subproblems.\n",
      "Action: None\n",
      "Thought: I need to calculate the number of people who need barber services, the total number of barber visits per year, the total number of customers a barber shop can serve per year, and the number of barber shops needed to serve the population.\n",
      "Action: Calculator\n",
      "Action Input: 9 million * 0.6, 5.4 million * 8.7, 30 customers/day * 300 days, 46.98 million visits / 9,000 customers/year\u001b[0m\n",
      "Observation: None\n",
      "Thought: I need to calculate the number of people who need barber services, the total number of barber visits per year, the total number of customers a barber shop can serve per year, and the number of barber shops needed to serve the population.\n",
      "Action: Calculator is not a valid tool, try another one.\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate the number of people who need barber services, the total number of barber visits per year, the total number of customers a barber shop can serve per year, and the number of barber shops needed to serve the population.\n",
      "Action: Pen and paper\n",
      "Action Input: 9 million * 0.6, 5.4 million * 8.7, 30 customers/day * 300 days, 46.98 million visits / 9,000 customers/year\u001b[0m\n",
      "Observation: Pen and paper is not a valid tool, try another one.\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate the number of people who need barber services, the total number of barber visits per year, the total number of customers a barber shop can serve per year, and the number of barber shops needed to serve the population.\n",
      "Action: Calculator\n",
      "Action Input: 9 million * 0.6, 5.4 million * 8.7, 30 customers/day * 300 days, 46.98 million visits / 9,000 customers/year\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 52394219.99999999\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: There are approximately 5,220 barber shops in London.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Tokens Used: 4166\n",
      "\tPrompt Tokens: 3767\n",
      "\tCompletion Tokens: 399\n",
      "Successful Requests: 5\n",
      "Total Cost (USD): $0.08332\n",
      "There are approximately 5,220 barber shops in London.\n"
     ]
    }
   ],
   "source": [
    "# Now let's test it out!\n",
    "my_question = \"\"\"**Assumptions**: Assume the Earth's ocean has an average depth of 3.7km and covers 71% of the Earth's surface. Assume the average density of fish in the ocean is 1 fish per 10 cubic meters of water.\n",
    "**Calculations**: Calculate the volume of the ocean by multiplying the surface area of the Earth by the average depth of the ocean. Then, divide the volume of water by 10 to get the estimated number of fish. \n",
    "Write an executable python program to find the result of t.\n",
    "\"\"\"\n",
    "my_question = '''Sure! Let's apply the Fermi estimation technique and break down the problem of estimating the number of barber shops in London into smaller, more manageable subproblems.\n",
    "\n",
    "1. Estimate the population of London: As of my knowledge cutoff in 2021, the population of London was around 9 million people.\n",
    "\n",
    "2. Estimate the number of households in London: We can assume an average of 2.5 people per household, similar to the previous example. This would give us approximately 3.6 million households (9 million / 2.5).\n",
    "\n",
    "3. Estimate the proportion of the population that needs barber services: We can assume that both men and women visit barber shops, but men might visit more frequently. Let's assume that 60% of the population needs barber services regularly.\n",
    "\n",
    "4. Estimate the frequency of barber shop visits: Let's assume that the average person who visits a barber shop does so once every 6 weeks, or roughly 8.7 times a year (52 weeks / 6).\n",
    "\n",
    "5. Estimate the number of customers a barber shop can serve in a day: Let's assume that a barber shop has 3 barbers, each of whom can serve 10 customers per day. This means a barber shop can serve 30 customers per day.\n",
    "\n",
    "6. Estimate the number of days a barber shop is open per year: Let's assume that a barber shop is open 6 days a week for 50 weeks a year, which is 300 days.\n",
    "\n",
    "Now, we can use these estimates to calculate the number of barber shops in London:\n",
    "\n",
    "1. Calculate the number of people who need barber services: 9 million * 0.6 = 5.4 million people\n",
    "2. Calculate the total number of barber visits per year: 5.4 million * 8.7 = 46.98 million visits\n",
    "3. Calculate the total number of customers a barber shop can serve per year: 30 customers/day * 300 days = 9,000 customers/year\n",
    "4. Estimate the number of barber shops needed to serve the population: 46.98 million visits / 9,000 customers/year = 5,220 barber shops\n",
    "\n",
    "So, using Fermi estimation and breaking down the problem recursively, we can estimate that there are approximately 5,220 barber shops in London. Keep in mind that this is a rough estimation and the actual number may vary.'''\n",
    "with get_openai_callback() as cb:\n",
    "    output = agent.run(my_question)\n",
    "    print(cb)\n",
    "print(output)\n",
    "\n",
    "# gpt3 will use natural log instead of proper log10\n",
    "# the right prompt will be: \"What is 32000 multiplied by 650 in the order of magnitude of 10?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse LLM output: `The template is just asking the assistant to repeat back the user's sentence, so no specific action is required.`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m sentence \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAssume the distance from Boston, MA to Portugal is 5,000 km. Assume the width of the bridge is 1 meter and the height is 0.5 meters. Assume the average thickness of a penny is 1.5 mm.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[39mwith\u001b[39;00m get_openai_callback() \u001b[39mas\u001b[39;00m cb:\n\u001b[1;32m---> 36\u001b[0m     output \u001b[39m=\u001b[39m agent_035\u001b[39m.\u001b[39;49mrun(prompt)\n\u001b[0;32m     37\u001b[0m     \u001b[39mprint\u001b[39m(cb)\n\u001b[0;32m     39\u001b[0m \u001b[39m# CLAIM: change temperature from 0 to 0.9 can revolve the math error - because it will stop using rounding expression!!\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m# if I use this prompt: \"What is 32000 multiplied by 650 in the order of magnitude of 10?\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[39m# conclusion: avoid letting the model generate expression like round()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:236\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    130\u001b[0m     inputs,\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:922\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m    921\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m--> 922\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[0;32m    923\u001b[0m         name_to_tool_map,\n\u001b[0;32m    924\u001b[0m         color_mapping,\n\u001b[0;32m    925\u001b[0m         inputs,\n\u001b[0;32m    926\u001b[0m         intermediate_steps,\n\u001b[0;32m    927\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[0;32m    928\u001b[0m     )\n\u001b[0;32m    929\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m    930\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[0;32m    931\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[0;32m    932\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:766\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    765\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors:\n\u001b[1;32m--> 766\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    767\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(e)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m    768\u001b[0m     observation \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInvalid or incomplete response\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:759\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Take a single step in the thought-action-observation loop.\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \n\u001b[0;32m    755\u001b[0m \u001b[39mOverride this to take control of how the agent makes and acts on choices.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    757\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    758\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m--> 759\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mplan(\n\u001b[0;32m    760\u001b[0m         intermediate_steps,\n\u001b[0;32m    761\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    762\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs,\n\u001b[0;32m    763\u001b[0m     )\n\u001b[0;32m    764\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    765\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors:\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:443\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    441\u001b[0m full_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    442\u001b[0m full_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfull_inputs)\n\u001b[1;32m--> 443\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_parser\u001b[39m.\u001b[39;49mparse(full_output)\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\mrkl\\output_parser.py:26\u001b[0m, in \u001b[0;36mMRKLOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     24\u001b[0m match \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msearch(regex, text, re\u001b[39m.\u001b[39mDOTALL)\n\u001b[0;32m     25\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m match:\n\u001b[1;32m---> 26\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not parse LLM output: `\u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m action \u001b[39m=\u001b[39m match\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m     28\u001b[0m action_input \u001b[39m=\u001b[39m match\u001b[39m.\u001b[39mgroup(\u001b[39m2\u001b[39m)\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse LLM output: `The template is just asking the assistant to repeat back the user's sentence, so no specific action is required.`"
     ]
    }
   ],
   "source": [
    "# initialize a chatGPT agent\n",
    "# First, let's load the language model we're going to use to control the agent. ()\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "gpt3_5 = ChatOpenAI(temperature=0.9,model_name=\"gpt-3.5-turbo\")\n",
    "# Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([], llm=gpt3_5)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent_035 = initialize_agent(tools, gpt3_5, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "## set up prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"sentence\"],\n",
    "    template=\"\"\"\\\n",
    "Assistant will repeat the sentence the user provides.\\\n",
    "Assistant will not engage in a conversation. Assistant will only repeat the sentence.\\\n",
    "SENTENCE: what is 32000 multiplied by 650 in the order of magnitude of 10?\n",
    "OUTPUT: what is 32000 multiplied by 650 in the order of magnitude of 10?\n",
    "\n",
    "SENTENCE: is there a way to get the result of t?\n",
    "OUTPUT: is there a way to get the result of t?\n",
    "\n",
    "SENTENCE: I don't want to do anything.\n",
    "OUTPUT: I don't want to do anything.\n",
    "\n",
    "SENTENCE: I want to do something.\n",
    "OUTPUT: I want to do something.\n",
    "\n",
    "SENTENCE: {sentence}\n",
    "QUESTION: \"\"\",\n",
    ")\n",
    "\n",
    "sentence = \"Assume the distance from Boston, MA to Portugal is 5,000 km. Assume the width of the bridge is 1 meter and the height is 0.5 meters. Assume the average thickness of a penny is 1.5 mm.\"\n",
    "with get_openai_callback() as cb:\n",
    "    output = agent_035.run(prompt)\n",
    "    print(cb)\n",
    "\n",
    "# CLAIM: change temperature from 0 to 0.9 can revolve the math error - because it will stop using rounding expression!!\n",
    "\n",
    "# if I use this prompt: \"What is 32000 multiplied by 650 in the order of magnitude of 10?\"\n",
    "# the second calculator action will use log instead of log10\n",
    "\n",
    "# if I use this prompt: \"What is 32000 multiplied by 650 in the order of magnitude of 10? Use log10\"\n",
    "# the first calculator action will use log10(32000*650) and second calculator action will result in error.\n",
    "\n",
    "# conclusion: avoid letting the model generate expression like round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to round the number to the nearest integer.\n",
      "Action: Calculator\n",
      "Action Input: round(7.318063349)\u001b[0m"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "LLMMathChain._evaluate(\"\nround(7.318063349)\n\") raised error: 'VariableNode' object is not callable. Please try again with a valid numerical expression",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\llm_math\\base.py:80\u001b[0m, in \u001b[0;36mLLMMathChain._evaluate_expression\u001b[1;34m(self, expression)\u001b[0m\n\u001b[0;32m     78\u001b[0m     local_dict \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mpi\u001b[39m\u001b[39m\"\u001b[39m: math\u001b[39m.\u001b[39mpi, \u001b[39m\"\u001b[39m\u001b[39me\u001b[39m\u001b[39m\"\u001b[39m: math\u001b[39m.\u001b[39me}\n\u001b[0;32m     79\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\n\u001b[1;32m---> 80\u001b[0m         numexpr\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m     81\u001b[0m             expression\u001b[39m.\u001b[39;49mstrip(),\n\u001b[0;32m     82\u001b[0m             global_dict\u001b[39m=\u001b[39;49m{},  \u001b[39m# restrict access to globals\u001b[39;49;00m\n\u001b[0;32m     83\u001b[0m             local_dict\u001b[39m=\u001b[39;49mlocal_dict,  \u001b[39m# add common mathematical functions\u001b[39;49;00m\n\u001b[0;32m     84\u001b[0m         )\n\u001b[0;32m     85\u001b[0m     )\n\u001b[0;32m     86\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numexpr\\necompiler.py:817\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(ex, local_dict, global_dict, out, order, casting, **kwargs)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[39mif\u001b[39;00m expr_key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _names_cache:\n\u001b[1;32m--> 817\u001b[0m     _names_cache[expr_key] \u001b[39m=\u001b[39m getExprNames(ex, context)\n\u001b[0;32m    818\u001b[0m names, ex_uses_vml \u001b[39m=\u001b[39m _names_cache[expr_key]\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numexpr\\necompiler.py:704\u001b[0m, in \u001b[0;36mgetExprNames\u001b[1;34m(text, context)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetExprNames\u001b[39m(text, context):\n\u001b[1;32m--> 704\u001b[0m     ex \u001b[39m=\u001b[39m stringToExpression(text, {}, context)\n\u001b[0;32m    705\u001b[0m     ast \u001b[39m=\u001b[39m expressionToAST(ex)\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numexpr\\necompiler.py:289\u001b[0m, in \u001b[0;36mstringToExpression\u001b[1;34m(s, types, context)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39m# now build the expression\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m ex \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m(c, names)\n\u001b[0;32m    290\u001b[0m \u001b[39mif\u001b[39;00m expressions\u001b[39m.\u001b[39misConstant(ex):\n",
      "File \u001b[1;32m<expr>:1\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'VariableNode' object is not callable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m gpt4 \u001b[39m=\u001b[39m ChatOpenAI(temperature\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,model_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-4\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m get_openai_callback() \u001b[39mas\u001b[39;00m cb:\n\u001b[0;32m      4\u001b[0m     \u001b[39m# output = agent_004.run(\"What is 32000 multiplied by 650 in the order of magnitude?\")\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     output \u001b[39m=\u001b[39m agent_004\u001b[39m.\u001b[39;49mrun(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRound this number to an integer: \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39m7.318063349\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(cb)\n\u001b[0;32m      7\u001b[0m \u001b[39m# output stores the final answer\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:236\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    130\u001b[0m     inputs,\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:922\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m    921\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m--> 922\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[0;32m    923\u001b[0m         name_to_tool_map,\n\u001b[0;32m    924\u001b[0m         color_mapping,\n\u001b[0;32m    925\u001b[0m         inputs,\n\u001b[0;32m    926\u001b[0m         intermediate_steps,\n\u001b[0;32m    927\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[0;32m    928\u001b[0m     )\n\u001b[0;32m    929\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m    930\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[0;32m    931\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[0;32m    932\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:800\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    798\u001b[0m         tool_run_kwargs[\u001b[39m\"\u001b[39m\u001b[39mllm_prefix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    799\u001b[0m     \u001b[39m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[1;32m--> 800\u001b[0m     observation \u001b[39m=\u001b[39m tool\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m    801\u001b[0m         agent_action\u001b[39m.\u001b[39;49mtool_input,\n\u001b[0;32m    802\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    803\u001b[0m         color\u001b[39m=\u001b[39;49mcolor,\n\u001b[0;32m    804\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    805\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtool_run_kwargs,\n\u001b[0;32m    806\u001b[0m     )\n\u001b[0;32m    807\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    808\u001b[0m     tool_run_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\tools\\base.py:255\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    254\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_error(e)\n\u001b[1;32m--> 255\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    256\u001b[0m run_manager\u001b[39m.\u001b[39mon_tool_end(\u001b[39mstr\u001b[39m(observation), color\u001b[39m=\u001b[39mcolor, name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    257\u001b[0m \u001b[39mreturn\u001b[39;00m observation\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\tools\\base.py:249\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    247\u001b[0m     tool_args, tool_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[0;32m    248\u001b[0m     observation \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 249\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39m*\u001b[39;49mtool_args, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtool_kwargs)\n\u001b[0;32m    250\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    251\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run(\u001b[39m*\u001b[39mtool_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtool_kwargs)\n\u001b[0;32m    252\u001b[0m     )\n\u001b[0;32m    253\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    254\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_error(e)\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\tools\\base.py:344\u001b[0m, in \u001b[0;36mTool._run\u001b[1;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Use the tool.\"\"\"\u001b[39;00m\n\u001b[0;32m    342\u001b[0m new_argument_supported \u001b[39m=\u001b[39m signature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 344\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\n\u001b[0;32m    345\u001b[0m         \u001b[39m*\u001b[39;49margs,\n\u001b[0;32m    346\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    347\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    348\u001b[0m     )\n\u001b[0;32m    349\u001b[0m     \u001b[39mif\u001b[39;00m new_argument_supported\n\u001b[0;32m    350\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:236\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    130\u001b[0m     inputs,\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\llm_math\\base.py:149\u001b[0m, in \u001b[0;36mLLMMathChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    143\u001b[0m _run_manager\u001b[39m.\u001b[39mon_text(inputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key])\n\u001b[0;32m    144\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(\n\u001b[0;32m    145\u001b[0m     question\u001b[39m=\u001b[39minputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key],\n\u001b[0;32m    146\u001b[0m     stop\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39m```output\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    147\u001b[0m     callbacks\u001b[39m=\u001b[39m_run_manager\u001b[39m.\u001b[39mget_child(),\n\u001b[0;32m    148\u001b[0m )\n\u001b[1;32m--> 149\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_llm_result(llm_output, _run_manager)\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\llm_math\\base.py:103\u001b[0m, in \u001b[0;36mLLMMathChain._process_llm_result\u001b[1;34m(self, llm_output, run_manager)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39mif\u001b[39;00m text_match:\n\u001b[0;32m    102\u001b[0m     expression \u001b[39m=\u001b[39m text_match\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 103\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate_expression(expression)\n\u001b[0;32m    104\u001b[0m     run_manager\u001b[39m.\u001b[39mon_text(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAnswer: \u001b[39m\u001b[39m\"\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    105\u001b[0m     run_manager\u001b[39m.\u001b[39mon_text(output, color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myellow\u001b[39m\u001b[39m\"\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[1;32mc:\\Users\\WTX\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\llm_math\\base.py:87\u001b[0m, in \u001b[0;36mLLMMathChain._evaluate_expression\u001b[1;34m(self, expression)\u001b[0m\n\u001b[0;32m     79\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\n\u001b[0;32m     80\u001b[0m         numexpr\u001b[39m.\u001b[39mevaluate(\n\u001b[0;32m     81\u001b[0m             expression\u001b[39m.\u001b[39mstrip(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m         )\n\u001b[0;32m     85\u001b[0m     )\n\u001b[0;32m     86\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m---> 87\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     88\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLLMMathChain._evaluate(\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mexpression\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m) raised error: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     89\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m Please try again with a valid numerical expression\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m     )\n\u001b[0;32m     92\u001b[0m \u001b[39m# Remove any leading and trailing brackets from the output\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[39mreturn\u001b[39;00m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m[|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m]$\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, output)\n",
      "\u001b[1;31mValueError\u001b[0m: LLMMathChain._evaluate(\"\nround(7.318063349)\n\") raised error: 'VariableNode' object is not callable. Please try again with a valid numerical expression"
     ]
    }
   ],
   "source": [
    "gpt4 = ChatOpenAI(temperature=0.5,model_name=\"gpt-4\")\n",
    "agent_004 = initialize_agent(tools, gpt4, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "with get_openai_callback() as cb:\n",
    "    # output = agent_004.run(\"What is 32000 multiplied by 650 in the order of magnitude?\")\n",
    "    output = agent_004.run(f\"Round this number to an integer: {7.318063349}\")\n",
    "    print(cb)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful tools for Fermi-aid:\n",
    "\n",
    "**python_repl** - a python shell\n",
    "**wolfram-alpha** - need app id to query wolfram-alpha\n",
    "**pal-math** - a LLM solving fully worded hard word math problem\n",
    "**llm-math** - a LLMMath chain instance\n",
    "**wikipedia** - use wikipedia python package to call MediaWiki API and parse results\n",
    "\n",
    "Other: ChatGPT Plugin, Hugging Face\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a customised chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "class ConcatenateChain(Chain):\n",
    "    chain_1: LLMChain\n",
    "    chain_2: LLMChain\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        # Union of the input keys of the two chains.\n",
    "        all_input_vars = set(self.chain_1.input_keys).union(set(self.chain_2.input_keys))\n",
    "        return list(all_input_vars)\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        return ['concat_output']\n",
    "\n",
    "    def _call(self, inputs: Dict[str, str]) -> Dict[str, str]:\n",
    "        output_1 = self.chain_1.run(inputs)\n",
    "        output_2 = self.chain_2.run(inputs)\n",
    "        return {'concat_output': output_1 + output_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConcatenateChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat is a good name for a company that makes colorful socks?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat is a good slogan for a company that makes colorful socks?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "Socktastic!\n",
      "\n",
      "\"Step Into Colorful Comfort!\"\n"
     ]
    }
   ],
   "source": [
    "prompt_1 = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "chain_1 = LLMChain(llm=llm, prompt=prompt_1,verbose=True)\n",
    "\n",
    "prompt_2 = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good slogan for a company that makes {product}?\",\n",
    ")\n",
    "chain_2 = LLMChain(llm=llm, prompt=prompt_2,verbose=True)\n",
    "\n",
    "concat_chain = ConcatenateChain(chain_1=chain_1, chain_2=chain_2, verbose=True)\n",
    "concat_output = concat_chain.run(\"colorful socks\")\n",
    "print(concat_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
