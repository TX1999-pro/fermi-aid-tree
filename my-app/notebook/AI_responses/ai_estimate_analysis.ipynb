{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 0527 - how good are GPT models in Fermi Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.27.6)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.30.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\wtx\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "     --------------------------------------- 10.6/10.6 MB 14.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\wtx\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "     ------------------------------------- 502.3/502.3 kB 10.5 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     ------------------------------------- 341.8/341.8 kB 10.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\wtx\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wtx\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.0.1 pytz-2023.3 tzdata-2023.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# dependency\n",
    "%pip install python-dotenv\n",
    "%pip install openai\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv # load keys from .env file\n",
    "import openai # use OpenAI API\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "        max_tokens=300, # this is the maximum number of tokens to generate\n",
    "    )\n",
    "    print(\">>>>RESPONSE>>>>\")\n",
    "    print(str(response.choices[0].message[\"content\"]))\n",
    "    print(\"<<<<END<<<<\")\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>RESPONSE>>>>\n",
      "Fermi estimation is a problem-solving technique that involves making rough estimates and approximations to arrive at a reasonable answer. It is named after the physicist Enrico Fermi, who was known for his ability to make quick and accurate estimates.\n",
      "\n",
      "The basic idea behind Fermi estimation is to break down a complex problem into simpler parts and make educated guesses about the values of the variables involved. For example, if you were asked to estimate the number of people in a city, you might start by estimating the population of a few neighborhoods and then extrapolating that to the entire city.\n",
      "\n",
      "To make a Fermi estimate, you typically follow these steps:\n",
      "\n",
      "1. Identify the key variables involved in the problem.\n",
      "2. Make educated guesses about the values of these variables.\n",
      "3. Use these guesses to calculate an approximate answer.\n",
      "4. Check your answer for reasonableness and adjust your estimates if necessary.\n",
      "\n",
      "Fermi estimation is often used in science, engineering, and business to quickly estimate the feasibility or cost of a project. It can also be a useful tool for making decisions when you don't have all the information you need.\n",
      "<<<<END<<<<\n"
     ]
    }
   ],
   "source": [
    "# Run this code block to get an example output\n",
    "prompt_example= f\"\"\"What is Fermi Estimation and how does it work?\"\"\"\n",
    "response = get_completion(prompt_example)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 1 - baseline (no context 0-shot)\n",
    "def prompt_1(question):\n",
    "    return f\"\"\"\\\n",
    "Here is a question: {question}. Give your reason and your estimated answer in the order of magnitute 10^x.\n",
    "Reason:\n",
    "Answer: x = ?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 2 - with classic example (rich context 1-shot)\n",
    "def prompt_2(question):\n",
    "    return f\"\"\"\\\n",
    "You are an AI assistant helping people practice Fermi estimation techniques.\\\n",
    "Fermi estimation is a problem-solving technique that involves making rough estimates and approximations to arrive at a reasonable answer.\n",
    "The basic idea behind Fermi estimation is to break down a complex problem into simpler parts and make educated guesses about the values of the variables involved.\n",
    "For example, if you were asked to estimate the number of people in a city, you might start by estimating the population of a few neighborhoods and then extrapolating that to the entire city.\n",
    "To make a Fermi estimate, you typically follow these steps:\n",
    "1. Identify the key variables involved in the problem.\n",
    "2. Make educated guesses about the values of these variables.\n",
    "3. Use these guesses to calculate an approximate answer.\n",
    "4. Check your answer for reasonableness and adjust your estimates if necessary.\n",
    "\n",
    "Here is a question: {question}. Give your reason and your estimated answer in the order of magnitute 10^x.\n",
    "Reason:\n",
    "Answer: x = ?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 3 - competence prompt: \"you KNOW the answer in the order of magnitude\" (context 0-shot)\n",
    "def prompt_3(question):\n",
    "    return f\"\"\"\\\n",
    "A curious learner is asking you a question:\n",
    "{question}\n",
    "You roughly know the answer in the order of magnitude, and you will teach the learner, step by step, how they can work out the answer themselves. Answer in the order of magnitude 10^x.\n",
    "Reason:\n",
    "Answer: x = ?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 4 - prompt with uncertainty \"you DON'T KNOW the exact answer, but you know it's in the order of magnitude of 10^x\" (context 0-shot)\n",
    "def prompt_4(question):\n",
    "    return f\"\"\"\\\n",
    "A curious learner is asking you a question:\n",
    "{question}\n",
    "You don't know the exact answer, but you will help the learner to work out a rough answer, step by step. Answer in the order of magnitude 10^x.\n",
    "Reason:\n",
    "Answer: x = ?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 5 - explicit step-by-step instruction (zero-shot)\n",
    "\n",
    "# ask LLM to give its estimation chain of thought.\n",
    "def prompt_5(question):\n",
    "    return f\"\"\"\\\n",
    "You are an AI assistant helping people practice Fermi estimation techniques.\\\n",
    "A human will post a question and ask for help to estimate a quantity in the order of magnitude.\\\n",
    "The estimation should rely on human's common senses and knowledge about the world.\n",
    "\n",
    "To make a Fermi estimate, you typically follow these steps as your reasons:\n",
    "1. Identify the final quantity of interest, T, or the target quantity, that needs to be estimated.\\\n",
    "2. Analyse factors will determine the answer to the target quantity, and name those sub-quantities.\\\n",
    "3. Logically link relevant factors together to create a mathematical model for computation.\n",
    "4. Present your final answer in the order of magnitude, in the form of 10^x, where x is the power of 10.\n",
    "\n",
    "Question: {question}\n",
    "Reason:\n",
    "Answer: x = ?\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection / query the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many hairs are on the average human head?\n",
      "What is the annual consumption of ice cream, in pounds, for the State of Ohio?\n",
      "How many toothpicks are required to cover a baseball diamond if the tooth picks are lying flat and sideby-side?\n",
      "The number of Earths that would fit inside of the sun?\n",
      "What is the maximum weight, in tons, of a Giant Sequoia tree?\n",
      "If every person who ever lived crowded together in one spot, how much area would be covered, in terms of the area of Rhode Island?\n",
      "If the annual interest that is owed on the national debt each year were divided equally amongst all U.S. citizens, how much would each citizen owe?\n",
      "How many lawyers are there in the United States?\n",
      "How many red blood cells are needed to blanket the surface area of an M&M?\n",
      "The My Lai Massacre occurred on this date in 1968. According to the US army, how many people were killed?\n",
      "How many car miles were avoided in 2010 by buses that took kids to school?\n",
      "How many tons one cubic cm of a neutron star would be?\n",
      "How many miles of railroad are operational in the U.S.?\n",
      "Hurricane Sandy was devastating and expensive. If you had a pile of pennies equal in value to Sandy's cost, what would be its weight in troy ounces?\n",
      "How many stacked 2 x 4 LEGO blocks would it take to reach the height of the Empire state Building?\n",
      "How many steps does the average American walk during their lifetime?\n",
      "According to the Census of Marine Life, with a membership of about 1000 scientists in 70 countries, what is the estimated number of life forms in the world's oceans?\n",
      "How many active volcanoes are on the surface of the earth?\n",
      "How many cups of coffee does Starbucks sell each year?\n",
      "Determine the density of oxygen in the air of this room at 25°C and 760 torr in g/L.\n"
     ]
    }
   ],
   "source": [
    "# sample questions from Eric\n",
    "# open json file\n",
    "file_path = 'C:/Users/WTX/workspace/fermi-aid-tree/my-app/src/data/Eric_FP_suggestion.json'\n",
    "\n",
    "def sample_questions(json_file):\n",
    "    with open(json_file, 'r', encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    questions = [entry['name'] for entry in data]\n",
    "    sampled_questions = random.sample(questions, 20)\n",
    "    return sampled_questions\n",
    "\n",
    "\n",
    "sampled_questions = sample_questions(file_path)\n",
    "for question in sampled_questions:\n",
    "    print(question) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query using prompt_1 on GPT3.5\n",
    "# write answers to a file for post analysis\n",
    "# query using prompt_1 on GPT4\n",
    "# write answers to a file for post analysis\n",
    "\n",
    "# Define your DataFrame columns\n",
    "columns = ['Question', 'Prompt_1_result', 'Prompt_2_result', 'Prompt_3_result', 'Prompt_4_result', 'Prompt_5_result']\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "counter = 0\n",
    "prompt_list = [prompt_1, prompt_2, prompt_3, prompt_4, prompt_5]\n",
    "\n",
    "for number, question in enumerate(sampled_questions[:10]):\n",
    "    # print(f\"Question {number+1}: {question}\")\n",
    "    # Create a dictionary to store the results for this question\n",
    "    results = {'Question': question}\n",
    "    \n",
    "    for index, prompt in enumerate(prompt_list[:5]):\n",
    "        # print(f\"Prompt {index+1}\")\n",
    "        try:\n",
    "            counter += 1\n",
    "            # Assuming that get_completion function returns the answer\n",
    "            # response = get_completion(prompt, model=model)\n",
    "            # For the sake of this example, let's say the response is 'Answer'\n",
    "            response = prompt(question)\n",
    "            # Add the result to the results dictionary\n",
    "            results[f'Prompt_{index+1}_result'] = response\n",
    "        except Exception as e:\n",
    "            print(\"===error message received===\")\n",
    "            print(e)\n",
    "            print(\"NEXT QUESTION\")\n",
    "            # Add 'ERROR' to the results dictionary\n",
    "            results[f'Prompt_{index+1}_result'] = 'ERROR'\n",
    "    # At the end of the inner loop, append the results to the DataFrame\n",
    "    df = pd.concat([df, pd.DataFrame([results])], ignore_index=True)\n",
    "print(df)\n",
    "df.to_csv('post_analysis.csv', index=False)\n",
    "\n",
    "with open('output.txt', 'w') as f:\n",
    "    for answer in df.values.flatten():\n",
    "        f.write(str(answer) + '\\n')\n",
    "        f.write(\"========================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's ROCK! with gpt-3.5-turbo\n",
      "                                            Question   \n",
      "0      How many hairs are on the average human head?  \\\n",
      "1  What is the annual consumption of ice cream, i...   \n",
      "\n",
      "                                     Prompt_1_result   \n",
      "0  You are an AI assistant helping people practic...  \\\n",
      "1  You are an AI assistant helping people practic...   \n",
      "\n",
      "                                     Prompt_2_result   \n",
      "0  You are an AI assistant helping people practic...  \\\n",
      "1  You are an AI assistant helping people practic...   \n",
      "\n",
      "                                     Prompt_3_result   \n",
      "0  You are an AI assistant helping people practic...  \\\n",
      "1  You are an AI assistant helping people practic...   \n",
      "\n",
      "                                     Prompt_4_result   \n",
      "0  You are an AI assistant helping people practic...  \\\n",
      "1  You are an AI assistant helping people practic...   \n",
      "\n",
      "                                     Prompt_5_result  \n",
      "0  You are an AI assistant helping people practic...  \n",
      "1  You are an AI assistant helping people practic...  \n"
     ]
    }
   ],
   "source": [
    "# looping through each model\n",
    "# looping through each prompt\n",
    "# looping through each question\n",
    "\n",
    "sampled_questions_text = \"\"\"How many hairs are on the average human head?\n",
    "What is the annual consumption of ice cream, in pounds, for the State of Ohio?\n",
    "How many toothpicks are required to cover a baseball diamond if the tooth picks are lying flat and sideby-side?\n",
    "The number of Earths that would fit inside of the sun?\n",
    "What is the maximum weight, in tons, of a Giant Sequoia tree?\n",
    "If every person who ever lived crowded together in one spot, how much area would be covered, in terms of the area of Rhode Island?\n",
    "If the annual interest that is owed on the national debt each year were divided equally amongst all U.S. citizens, how much would each citizen owe?\n",
    "How many lawyers are there in the United States?\n",
    "How many red blood cells are needed to blanket the surface area of an M&M?\n",
    "The My Lai Massacre occurred on this date in 1968. According to the US army, how many people were killed?\n",
    "How many car miles were avoided in 2010 by buses that took kids to school?\n",
    "How many tons one cubic cm of a neutron star would be?\n",
    "How many miles of railroad are operational in the U.S.?\n",
    "Hurricane Sandy was devastating and expensive. If you had a pile of pennies equal in value to Sandy's cost, what would be its weight in troy ounces?\n",
    "How many stacked 2 x 4 LEGO blocks would it take to reach the height of the Empire state Building?\n",
    "How many steps does the average American walk during their lifetime?\n",
    "According to the Census of Marine Life, with a membership of about 1000 scientists in 70 countries, what is the estimated number of life forms in the world's oceans?\n",
    "How many active volcanoes are on the surface of the earth?\n",
    "How many cups of coffee does Starbucks sell each year?\n",
    "Determine the density of oxygen in the air of this room at 25°C and 760 torr in g/L.\"\"\"\n",
    "def string_to_list(input_string):\n",
    "    return input_string.split('\\n')\n",
    "\n",
    "\n",
    "# prepare output in a csv file\n",
    "\n",
    "# start querying\n",
    "sampled_questions=string_to_list(sampled_questions_text)\n",
    "# Define your DataFrame columns\n",
    "columns = ['Question', 'Prompt_1_result', 'Prompt_2_result', 'Prompt_3_result', 'Prompt_4_result', 'Prompt_5_result']\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "counter = 0\n",
    "prompt_list = [prompt_1, prompt_2, prompt_3, prompt_4, prompt_5]\n",
    "model = 'gpt-3.5-turbo'\n",
    "print(f\"Let's ROCK! with {model}\")\n",
    "for number, question in enumerate(sampled_questions[:2]):\n",
    "    # print(f\"Question {number+1}: {question}\")\n",
    "    # Create a dictionary to store the results for this question\n",
    "    results = {'Question': question}\n",
    "    \n",
    "    for index, prompt in enumerate(prompt_list[:5]):\n",
    "        # print(f\"Prompt {index+1}\")\n",
    "        try:\n",
    "            counter += 1\n",
    "            # Assuming that get_completion function returns the answer\n",
    "            # response = get_completion(prompt, model=model)\n",
    "            # Add the result to the results dictionary\n",
    "            results[f'Prompt_{index+1}_result'] = response\n",
    "        except Exception as e:\n",
    "            print(\"===error message received===\")\n",
    "            print(e)\n",
    "            print(\"NEXT QUESTION\")\n",
    "            # Add 'ERROR' to the results dictionary\n",
    "            results[f'Prompt_{index+1}_result'] = 'ERROR'\n",
    "    # At the end of the inner loop, append the results to the DataFrame\n",
    "    df = pd.concat([df, pd.DataFrame([results])], ignore_index=True)\n",
    "\n",
    "# console output\n",
    "print(df)\n",
    "# save data to csv for post analysis\n",
    "df.to_csv('post_analysis.csv', index=False)\n",
    "# save flattened data to txt file for easy copy-paste\n",
    "with open('output.txt', 'w') as f:\n",
    "    for answer in df.values.flatten():\n",
    "        f.write(str(answer) + '\\n')\n",
    "        f.write(\"========================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
