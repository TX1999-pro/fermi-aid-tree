//"use client";
import useLLM from "usellm";
import { useState } from "react";
export default function LLMChatDemo(props) {
    const llm = useLLM({ serviceUrl: "https://usellm.org/api/llm" });
    const [result, setResult] = useState("");
    async function handleClick() {
        setResult("Loading...");
        try {
            await llm.chat({
                messages: [{ role: "user", content: props.query }],
                stream: true,
                onStream: ({ message }) => setResult(message.content),
            });
        } catch (error) {
            console.error("Something went wrong!", error);
            setResult("Something went wrong! Please try again later.");
        }
    }
    return (
        <div>
            <button onClick={handleClick}>ASK AI</button>
            {(result !== "") &&
                <div style={{ whiteSpace: "pre-wrap" }}>
                    {result}
                    <p>Note that information and answers generated by AI may not be truthful and should be reviewed with caution.</p>
                </div>}

        </div>
    );
}